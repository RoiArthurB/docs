---
sidebar_position: 7
---

# Handle video stream

## With `@yume-chan/scrcpy`

If you have a `ReadableStream<Uint8Array>` that reads from the video socket, use `options` to parse the metadata and create a packet stream.

```ts transpile
import { ScrcpyOptions2_1, ScrcpyVideoStreamPacket } from "@yume-chan/scrcpy";

const options = new ScrcpyOptions2_1({
  // use the same version and options when starting the server
});

const videoSocket: ReadableStream<Uint8Array>; // get the stream yourself

// Parse video socket metadata
const { metadata: videoMetadata, stream: videoStream } =
  await options.parseVideoStreamMetadata(videoSocket);

const videoPacketStream: ReadableStream<ScrcpyMediaStreamPacket> =
  videoStream.pipeThrough(options.createMediaStreamTransformer());

videoPacketStream
  .pipeTo(
    new WritableStream({
      write(packet: ScrcpyMediaStreamPacket) {
        switch (packet.type) {
          case "configuration":
            // Handle configuration packet
            console.log(packet.data);
            break;
          case "data":
            // Handle data packet
            console.log(packet.keyframe, packet.pts, packet.data);
            break;
        }
      },
    })
  )
  .catch((e) => {
    console.error(e);
  });
```

Similar to `options.clipboard`, don't `await` the `pipeTo`. You need to read multiple streams at the same time, but the returned `Promise` will only resolve when `videoSocket` ends.

### Metadata

The `metadata` object contains information like the video codec and initial video size.

```ts
interface ScrcpyVideoStreamMetadata {
  deviceName?: string | undefined;
  width?: number | undefined;
  height?: number | undefined;
  codec: ScrcpyVideoCodecId;
}
```

Some fields are dependent on the server version and options:

| Version | `deviceName`                                   | `width` and `height`                           | `codec`                                                                                                 |
| ------- | ---------------------------------------------- | ---------------------------------------------- | ------------------------------------------------------------------------------------------------------- |
| v1.15   | Always present                                 | Always present                                 | Always `H264`                                                                                           |
| v1.22   | Present when `sendDeviceMeta` option is `true` | Present when `sendDeviceMeta` option is `true` | Always `H264`                                                                                           |
| v2.0    | Present when `sendDeviceMeta` option is `true` | Present when `sendCodecMeta` option is `true`  | Value from server when `sendCodecMeta` is `true`, or value from options when `sendCodecMeta` is `false` |

It's recommended to parse `width` and `height` from the video stream itself, as then device orientation changes, the video size will be updated.

### Media Stream

When `sendFrameMeta` option is `false`, `videoPacketStream` will not contain `configuration` packets, and in `data` packets, `keyframe` and `pts` fields will always be `undefined`.

In other words, it only contains the raw video data. This stream can be used with some advanced decoders like FFmpeg, who can detect configuration and keyframes from a raw stream.

When `sendFrameMeta` option is `true` (the default value), there will be both `configuration` and `data` packets in the stream. The `keyframe` and `pts` fields will be populated in `data` packets.

- `configuration` packets are guaranteed to be the first packet in the stream. It contains the video codec configuration. It will be occasionally sent again when video encoder is restarted (e.g. when the device orientation changes).
- `data` packets contain the video frames. The `keyframe` field indicates whether it's a keyframe or not. The `pts` field is the presentation timestamp of the frame. Each `data` packet will contain a complete frame.

## With `@yume-chan/adb-scrcpy`

When video is enabled (`video: false` not exist in options), `AdbScrcpyClient.videoStream` is a `Promise` that resolves to an `AdbScrcpyVideoStream`.

```ts
interface AdbScrcpyVideoStream {
  stream: ReadableStream<ScrcpyMediaStreamPacket>;
  metadata: ScrcpyVideoStreamMetadata;
}
```

It's very similar to the `videoMetadata` and `videoPacketStream` values in the above example, as `videoStream` calls `parseVideoStreamMetadata` and `createMediaStreamTransformer` internally.

```ts transpile
if (client.videoSteam) {
  const { metadata: videoMetadata, stream: videoPacketStream } =
    await client.videoStream;

  videoPacketStream
    .pipeTo(
      new WritableStream({
        write(packet: ScrcpyMediaStreamPacket) {
          switch (packet.type) {
            case "configuration":
              // Handle configuration packet
              console.log(packet.data);
              break;
            case "data":
              // Handle data packet
              console.log(packet.keyframe, packet.pts, packet.data);
              break;
          }
        },
      })
    )
    .catch((e) => {
      console.error(e);
    });
}
```

Check the [With `@yume-chan/scrcpy`](#with-yume-chanscrcpy) section above for how to handle different types of packets.

## Decode and render video

Tango provides packages to decode and render video packets in Web browsers:

- [Tiny H264 decoder](/scrcpy/video/tiny-h264)
- [WebCodecs decoder](/scrcpy/video/web-codecs)

To use these decoders, the `sendFrameMeta` options must be `true` (the default value).

Decoding and playing video outside the browser is out of scope for this library. It will depend on the platform, UI framework, and media library you use.
